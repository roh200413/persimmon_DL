{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra \n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) \n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image , ImageDraw \n",
    "from sklearn.preprocessing import * \n",
    "import time \n",
    "import ast \n",
    "import os \n",
    "import keras \n",
    "import tensorflow as tf \n",
    "from keras import models, layers \n",
    "from keras import Input \n",
    "from keras.models import Model, load_model \n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras import optimizers, initializers, regularizers, metrics \n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping \n",
    "from keras.layers import BatchNormalization, Conv2D, Activation , AveragePooling2D , Input ,Dropout \n",
    "from keras.layers import Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add, Flatten \n",
    "from keras.models import Sequential \n",
    "from keras.metrics import top_k_categorical_accuracy \n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping \n",
    "from keras.applications import ResNet50, vgg19,mobilenet_v2,InceptionV3 , InceptionResNetV2,DenseNet169 \n",
    "from tqdm import tqdm \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 940/940 [00:00<00:00, 478476.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BackBad</td>\n",
       "      <td>BackBad.0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BackBad</td>\n",
       "      <td>BackBad.1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BackBad</td>\n",
       "      <td>BackBad.10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BackBad</td>\n",
       "      <td>BackBad.100.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BackBad</td>\n",
       "      <td>BackBad.101.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label              img\n",
       "0  BackBad    BackBad.0.jpg\n",
       "1  BackBad    BackBad.1.jpg\n",
       "2  BackBad   BackBad.10.jpg\n",
       "3  BackBad  BackBad.100.jpg\n",
       "4  BackBad  BackBad.101.jpg"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path ='C:/Users/sdf80/Desktop/fruit_dataset/TotalClass/'\n",
    "filename = os.listdir(path)\n",
    "datalist = pd.DataFrame(data=[], columns=['label','img'])\n",
    "\n",
    "label = []\n",
    "img = []\n",
    "\n",
    "for file in tqdm(filename):\n",
    "    label.append(file.split('.')[0])\n",
    "    img.append(file)\n",
    "    \n",
    "datalist['label'] = label\n",
    "datalist['img'] = img\n",
    "\n",
    "datalist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23e5ec2f130>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWlklEQVR4nO3df5TVdZ3H8edLILGkEhhdBLbhtJQLbuI6oa6eguysqLVY6w88HsM9ttg5mrmbtVhb2Ra79kM9W2Ybrgpb/kLNxB+ZSmq5R8VBUUCkUFFHWBjIykxIhvf+8f2MfB3uzNy5dy4MH1+Pc+653/v5/vp87vfe1/3cz/1+ZxQRmJlZXvbY1RUwM7P+53A3M8uQw93MLEMOdzOzDDnczcwyNHhXVwBg5MiR0dzcvKurYWa2W1myZMnGiGiqNG9AhHtzczOtra27uhpmZrsVSc91N8/DMmZmGXK4m5llyOFuZpahATHmbmb2Zvfaa6/R1tbG5s2bd5g3dOhQxowZw5AhQ6rensPdzGwAaGtrY9iwYTQ3NyPp9fKIYNOmTbS1tTFu3Liqt+dhGTOzAWDz5s2MGDHiDcEOIIkRI0ZU7NH3xOFuZjZAdA323sp74nA3M8uQw93MLEP+QdXMstQ8+/ZdXYWqrLnwuNenI6LiEEwt/1TJPXczswFg6NChbNq0aYcg7zxbZujQoX3annvuZmYDwJgxY2hra6O9vX2HeZ3nufeFw93MbAAYMmRIn85j742HZczMMuRwNzPLkIdlzGqwO56JYW8u7rmbmWWo13CXNFTSYkmPS1oh6aupfLikuyX9Ot3vU1rnfEmrJa2SdHQjG2BmZjuqpue+BfhQRBwETAKmSToMmA0siojxwKL0GEkTgBnARGAacJmkQY2ovJmZVdZruEfhD+nhkHQLYDowP5XPB45P09OB6yJiS0Q8C6wGJvdrrc3MrEdVjblLGiRpKbABuDsiHgb2i4h1AOl+37T4aOCF0uptqazrNmdJapXUWumkfTMzq11V4R4RHRExCRgDTJZ0YA+LV/rblDv8YYSImBsRLRHR0tTUVF1tzcysKn06WyYifgvcRzGWvl7SKIB0vyEt1gaMLa02Blhbd03NzKxq1Zwt0yTpnWl6L+DDwFPAQmBmWmwmcEuaXgjMkLSnpHHAeGBxf1fczMy6V81FTKOA+emMlz2ABRFxm6QHgQWSzgCeB04EiIgVkhYATwJbgbMioqMx1Tczs0p6DfeIeAI4uEL5JuCobtaZA8ypu3ZmZlYTX6FqZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llqNdwlzRW0r2SVkpaIekzqfwCSS9KWppux5bWOV/SakmrJB3dyAaYmdmOBlexzFbgsxHxqKRhwBJJd6d5l0TEt8sLS5oAzAAmAvsD90h6T0R09GfFzcyse7323CNiXUQ8mqZfBlYCo3tYZTpwXURsiYhngdXA5P6orJmZVadPY+6SmoGDgYdT0dmSnpB0paR9Utlo4IXSam1U+DCQNEtSq6TW9vb2PlfczMy6V3W4S9obuAk4NyJ+D3wfeDcwCVgHXNS5aIXVY4eCiLkR0RIRLU1NTX2uuJmZda+qcJc0hCLYr46IHwNExPqI6IiIbcDlbB96aQPGllYfA6ztvyqbmVlvqjlbRsAVwMqIuLhUPqq02MeA5Wl6ITBD0p6SxgHjgcX9V2UzM+tNNWfLHAGcBiyTtDSVfQE4RdIkiiGXNcCZABGxQtIC4EmKM23O8pkyZmY7V6/hHhEPUHkc/Y4e1pkDzKmjXmZmVgdfoWpmliGHu5lZhhzuZmYZcribmWXI4W5mliGHu5lZhhzuZmYZcribmWXI4W5mliGHu5lZhhzuZmYZcribmWXI4W5mliGHu5lZhhzuZmYZcribmWXI4W5mliGHu5lZhhzuZmYZcribmWXI4W5mliGHu5lZhhzuZmYZ6jXcJY2VdK+klZJWSPpMKh8u6W5Jv073+5TWOV/SakmrJB3dyAaYmdmOqum5bwU+GxF/CRwGnCVpAjAbWBQR44FF6TFp3gxgIjANuEzSoEZU3szMKus13CNiXUQ8mqZfBlYCo4HpwPy02Hzg+DQ9HbguIrZExLPAamByf1fczMy616cxd0nNwMHAw8B+EbEOig8AYN+02GjghdJqbanMzMx2kqrDXdLewE3AuRHx+54WrVAWFbY3S1KrpNb29vZqq2FmZlWoKtwlDaEI9qsj4sepeL2kUWn+KGBDKm8DxpZWHwOs7brNiJgbES0R0dLU1FRr/c3MrIJqzpYRcAWwMiIuLs1aCMxM0zOBW0rlMyTtKWkcMB5Y3H9VNjOz3gyuYpkjgNOAZZKWprIvABcCCySdATwPnAgQESskLQCepDjT5qyI6Oj3mpuZWbd6DfeIeIDK4+gAR3WzzhxgTh31MjOzOvgKVTOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEO9hrukKyVtkLS8VHaBpBclLU23Y0vzzpe0WtIqSUc3quJmZta9anru84BpFcoviYhJ6XYHgKQJwAxgYlrnMkmD+quyZmZWnV7DPSJ+Afymyu1NB66LiC0R8SywGphcR/3MzKwG9Yy5ny3piTRss08qGw28UFqmLZXtQNIsSa2SWtvb2+uohpmZdVVruH8feDcwCVgHXJTKVWHZqLSBiJgbES0R0dLU1FRjNczMrJKawj0i1kdER0RsAy5n+9BLGzC2tOgYYG19VTQzs76qKdwljSo9/BjQeSbNQmCGpD0ljQPGA4vrq6KZmfXV4N4WkHQtMAUYKakN+AowRdIkiiGXNcCZABGxQtIC4ElgK3BWRHQ0pupmZtadXsM9Ik6pUHxFD8vPAebUUykzM6uPr1A1M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwyNLi3BSRdCXwE2BARB6ay4cD1QDOwBjgpIl5K884HzgA6gHMi4mcNqbmZ9Zvm2bfv6ipUZc2Fx+3qKuw2qum5zwOmdSmbDSyKiPHAovQYSROAGcDEtM5lkgb1W23NzKwqvYZ7RPwC+E2X4unA/DQ9Hzi+VH5dRGyJiGeB1cDkfqqrmZlVqdYx9/0iYh1Aut83lY8GXigt15bKdiBplqRWSa3t7e01VsPMzCrp7x9UVaEsKi0YEXMjoiUiWpqamvq5GmZmb261hvt6SaMA0v2GVN4GjC0tNwZYW3v1zMysFr2eLdONhcBM4MJ0f0up/BpJFwP7A+OBxfVW8s3GZy6YWb2qORXyWmAKMFJSG/AVilBfIOkM4HngRICIWCFpAfAksBU4KyI6GlR3MzPrRq/hHhGndDPrqG6WnwPMqadSZmZWH1+hamaWIYe7mVmGHO5mZhlyuJuZZcjhbmaWIYe7mVmGar2IyaxqvijLbOdzz93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8tQXf+sQ9Ia4GWgA9gaES2ShgPXA83AGuCkiHipvmqamVlf9EfPfWpETIqIlvR4NrAoIsYDi9JjMzPbiRoxLDMdmJ+m5wPHN2AfZmbWg3rDPYC7JC2RNCuV7RcR6wDS/b6VVpQ0S1KrpNb29vY6q2FmZmX1/oPsIyJiraR9gbslPVXtihExF5gL0NLSEnXWw8zMSurquUfE2nS/AbgZmAyslzQKIN1vqLeSZmbWNzWHu6S3SRrWOQ38LbAcWAjMTIvNBG6pt5JmZtY39QzL7AfcLKlzO9dExJ2SHgEWSDoDeB44sf5qmplZX9Qc7hHxDHBQhfJNwFH1VMrMzOrjK1TNzDLkcDczy5DD3cwsQw53M7MMOdzNzDJU7xWqA0Lz7Nt3dRWqsubC43Z1FczsTcI9dzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy1LBwlzRN0ipJqyXNbtR+zMxsRw0Jd0mDgO8BxwATgFMkTWjEvszMbEeN6rlPBlZHxDMR8SfgOmB6g/ZlZmZdKCL6f6PSCcC0iPhkenwacGhEnF1aZhYwKz18L7Cq3ytSn5HAxl1diX7k9gx8ubUpt/bAwGvTuyKiqdKMwQ3aoSqUveFTJCLmAnMbtP+6SWqNiJZdXY/+4vYMfLm1Kbf2wO7VpkYNy7QBY0uPxwBrG7QvMzProlHh/ggwXtI4SW8BZgALG7QvMzProiHDMhGxVdLZwM+AQcCVEbGiEftqoAE7ZFQjt2fgy61NubUHdqM2NeQHVTMz27V8haqZWYYc7mZmGRrw4S6pQ9LS0q25H7Z5rqS3lh6vkXRT6fEJkubVu58+1mleuj5gZ7Z5Wdr+Mkl9ushM0umSLu1S38clPSrpb2qs4+vPQZfy+yS1lh63SLqvln3UStIFks4rPd4ZbV6V9rEyXRfSl+1OkXRbhfIvSloh6Ym07UMl/XelK8jLx7iH/ZwuaZuk95XKlvfHa7ZakpolLe9hfiPa3J62tULSjeX3VpV1XiNpZF/W6atGnefen16NiEmVZkgSxe8G2/q4zXOBHwF/LJW1SJpYyw+/kgZHxNa+rteDndXmqRGxUdJ7gbuAW2qqbam+ko4G/gP4YI3b6s6+ko6JiJ/2dcUGHB/YOW0+NSJaJQ0HnpY0L13xXRNJhwMfAf46IrakcHlL58WGdWgDvgicXGO9BkVER5116G7bjWrz9Z0XZUq6hqLtV9W5zX414HvuXaVP6ZWSLgMeBcZK+lbqLSyTdHJabkrq/dwo6SlJV6twDrA/cK+ke0ub/jbwhQr7Gy7pJ+lT/6HOHkrqyc2VdBfwP+nxfEl3pU/lj0v6ZqrTnZKGpPW+LOmRVN+5Kax3VZs7vR14qbS/n0haknols0rl/yDpV5LuB47oprqvb0vS3pIWqejZvuHbgaRPpOf0cUk/rNDmr6no1Xa+Rr8F/GuF5YZKuipt/zFJU1P56ZJukHQrcFd6/BNJt0p6VtLZkv45rfNQClAk/WM6Po9LuqnKHlmj2txpb+AVoCMt931Jren4fLW0/rR03B8APl6hnqOAjRGxBSAiNkbE2vSaaUnbqHiMJTWl5+ORdCsf/9uAiSo6CV3bdEp6HpZL+kap/A+S/k3Sw8Dh6fE30uvuHkmTU72ekfR3aZ1mSb9Mz22135Ya1ebOZQYDb2P78f+opIfT6+oeSful8hEqsuExST+g8oWe/SsiBvSN4gW9NN1uBpqBbcBhaf7fA3dTnHK5H/A8xQGdAvyO4gKqPYAHgSPTOmuAkaV9rEnrrgT+AjgBmJfmfRf4Spr+ELA0TV8ALAH2Kj1+ABgCHETRQz4mzbsZOD5NDy/t94fAR9P0POCEndzmZcDyVNePlOYNT/d7pfkj0vafB5qAtwD/C1zapb5Ppf0fksoHA29P0yOB1RQv6okUf25iZJf9zUvP/TeBH7D9bK77gBbg58DUNH1fmvdZ4Ko0fUCq41DgdIoeZee2T0/7H5ba8DvgU2neJcC5aXpE6Xn4OvDp0vE9r8LrspFtXgU8AbwKnFnh+AxKy70vtfkFYHza3wLgti7vpb1TnX8FXAZ8sMvz29Mxvobtr6U/B1aWntdLgU8A81PZcorX7P6l7Q1Ox6/zfRDASaW6BW98v9zF9vdS53vurcDQND0eaE3TzcDybvKjUW1uT9tdD/wSGJTm7VM6hp8ELkrT3wG+nKaPS+0dWanO/XXbHXrur0bEpHT7WCp7LiIeStNHAtdGREdErAfuB96f5i2OiLYohjCWUrwIutNB0Ts8v0v5kRQhTET8HBgh6R1p3sKIeLW07E8j4jWK0BwE3JnKl5X2PTV9si+j+LCYuAvbPDUiDgT+CrhU0t6p/BxJjwMPUVxpPB44lCJQ26MYGri+Qn0PAKZRfJMRRcj8u6QngHuA0RQfRh8CboyIjel5/U1pW18C3hkRZ0Z6J5R8nR177+Xj8xTwHPCeNO/uLtu+NyJejoh2ikC+NZWXj8+BqXe4DDiVysdnZ7X51Ih4H0WwnCfpXan8JEmPAo+l+k2g+GB7NiJ+nbbxo64Vjog/AIdQ/E2nduB6SaeXFunpGH+Y4jWylOKCxLdLGlaafw1wmKRxpbL3l7a3Fbga+ECa1wHcVFr2T7zx/XJ/6b3UnMqHAJenY3NDanePGtjm66MYlvuzVMfPpfIxwM9SHT/H9tfPB0jHJCJup/RNuVF2hzH3Sl4pTff09WZLabqD3tv7Q4pwL4+79/R3cl7pUt751W+bpNdKb9RtwGBJQyl6Dy0R8YKkCyh6XNVoVJuJiKclrQcmpGGIDwOHR8QfVfxw2VnHXi+KiIgHVYxrNgHHpvtDIuI1SWvSttTDth4BDpE0vEsAEhE/l/Q14LBScU/PRcXjk2wrPd7G9udpHkXv8vEUAlN62H5nvRrW5rT99hTmh6Yhm/OA90fESyp++O/L8emg6LXelwJoZtdFull1D4rXRLkzg9KoYhQXLl4E/Et5dg9V2RxvHGfv+n4pv5c6j80/UfSUD0r12dzD9l/XqDanbYeKob9PAxdSfNO/OCIWSppC8Y2vt/00xO7Qc+/NL4CTJQ2S1ETxCbm4l3Vepvh6/gapp3AJxY+P5e2fCsWYNsX43e9rrGvnm3Bj6iXvcJZElfqtzQCS9gXGUfR63wG8lIL9ALYH6cPAlDR2OAQ4sZttHUDxrWVT2taGFHJTgc6e5yKK3ueItM7w0ibupHiT3N6lZ9hpDvD50uPy8XkPRS+3nr8wOgxYl9p4ajUrNLrN6QP3YOBpivH9V4DfpfHcY9JiTwHjJL07PT6lwnbeK2l8qWgSxTHv1NMxvgso/1XXSj/4z6PoGHT+lcKHgQ9KGqnifzycQvEts1bvANalb6WnUTznPdoJbYbi2+PTpTq+mKbLHyLl1+kxFMM3DbW79tzLbgYOBx6n+GT8fET8X3rDdWcu8FNJ6yJiapd5V/DGr/4XAFelr9l/ZMdP/apFxG8lXU7xNW4NRY+tFv3V5nsldVB83Z0dEesl3Ql8KrV3FcXQDBGxLn3TeBBYR/HDbueba6/01RWK3trMiOiQdDVwq4rTGDvHp4mIFZLmAPen/T9GMY5Jmn9DCrmFko4tNyIi7pDUXiq6DPiv1CPbCpwexVkRvT+LlX2J4g3/HMVxqviBuJPafLWkV4E9KX4DWgIg6TGKb5fPUIwRExGbVfz4fbukjRS//xzYpc57A9+V9E6K52o1xXDFjWkbPR3jc4DvpdfFYIqw+lR54xHxJ0nfAf6ztL3zgXvTc3RHRNR6RhYUx/omSSembXb9ZlZJo9p8sqQjKTrIbWw/lhcAN0h6keK90zlM9VXg2vQN7H6Kcf6G8p8fMDPLUA7DMmZm1oXD3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53M7MM/T+JvApECNKSxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "FrontNormalNum = 0 \n",
    "FrontBadNum = 0\n",
    "BackNormalNum = 0 \n",
    "BackBadNum = 0\n",
    "SideNormalNum = 0\n",
    "SideBadNum = 0\n",
    "\n",
    "for i in datalist['label']:\n",
    "    if i == 'FrontNormal':\n",
    "        FrontNormalNum += 1\n",
    "    if i == 'FrontBad':\n",
    "        FrontBadNum += 1\n",
    "    if i == 'BackNormal':\n",
    "        BackNormalNum += 1\n",
    "    if i == 'BackBad':\n",
    "        BackBadNum += 1\n",
    "    if i == 'SideNormal':\n",
    "        SideNormalNum += 1\n",
    "    if i == 'SideBad':\n",
    "        SideBadNum += 1    \n",
    "        \n",
    "plt.bar(['FrontNormal', 'FrontBad', 'BackNormal', 'BackBad', 'SideNormal', 'SideBad'], [FrontNormalNum, FrontBadNum, BackNormalNum, BackBadNum, SideNormalNum, SideBadNum])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrontNormal Count\n",
      "34\n",
      "FrontBad Count\n",
      "95\n",
      "BackNormal Count\n",
      "81\n",
      "BackBad Count\n",
      "308\n",
      "SideNormal Count\n",
      "104\n",
      "SideBad Count\n",
      "318\n",
      "Total Count\n",
      "940\n"
     ]
    }
   ],
   "source": [
    "print('FrontNormal Count')\n",
    "print(datalist[datalist['label'] =='FrontNormal']['label'].count())\n",
    "\n",
    "print('FrontBad Count')\n",
    "print(datalist[datalist['label'] =='FrontBad']['label'].count())\n",
    "\n",
    "print('BackNormal Count')\n",
    "print(datalist[datalist['label'] =='BackNormal']['label'].count())\n",
    "\n",
    "print('BackBad Count')\n",
    "print(datalist[datalist['label'] =='BackBad']['label'].count())\n",
    "\n",
    "print('SideNormal Count')\n",
    "print(datalist[datalist['label'] =='SideNormal']['label'].count())\n",
    "\n",
    "print('SideBad Count')\n",
    "print(datalist[datalist['label'] =='SideBad']['label'].count())\n",
    "\n",
    "print('Total Count')\n",
    "print(datalist['label'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(path) :\n",
    "    X = []\n",
    "    Y = []\n",
    "    class_label = []\n",
    "    class_num = 6\n",
    "    \n",
    "    for num in tqdm(range(len(datalist['img']))) :\n",
    "        img = cv2.imread(path+datalist['img'][num])\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img,(160,160))\n",
    "        \n",
    "        if datalist['label'][num] == 'FrontNormal': \n",
    "            X.append(img) \n",
    "            Y.append(0) \n",
    "        elif  datalist['label'][num] == 'FrontBad': \n",
    "            X.append(img) \n",
    "            Y.append(1)\n",
    "        elif  datalist['label'][num] == 'BackNormal': \n",
    "            X.append(img) \n",
    "            Y.append(2)\n",
    "        elif  datalist['label'][num] == 'BackBad': \n",
    "            X.append(img) \n",
    "            Y.append(3)\n",
    "        elif  datalist['label'][num] == 'SideNormal': \n",
    "            X.append(img) \n",
    "            Y.append(4)\n",
    "        else:\n",
    "            X.append(img) \n",
    "            Y.append(5)\n",
    "\n",
    "    tmpx = np.array(X) \n",
    "    Y = np.array([[i] for i in Y]) \n",
    "    enc = OneHotEncoder(categories='auto') \n",
    "    enc.fit(Y) \n",
    "    tmpy = enc.transform(Y).toarray() \n",
    "\n",
    "    del X \n",
    "    del Y #RAM메모리 절약을 위해 사용하지 않는 변수 삭제\n",
    "    return tmpx , tmpy , class_label , class_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 940/940 [00:02<00:00, 340.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(940, 160, 160, 3) (940, 6)\n"
     ]
    }
   ],
   "source": [
    "tmpx, tmpy, class_label, class_num = preprocessing(path) \n",
    "#파일이름이 담긴 배열 \n",
    "print(tmpx.shape, tmpy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(752, 160, 160, 3) (188, 160, 160, 3) (752, 6) (188, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_val, Y_train, Y_val = train_test_split(tmpx,tmpy, test_size = 0.2,random_state = 1) \n",
    "del tmpx \n",
    "del tmpy #RAM메모리 절약을 위해 사용하지 않는 변수 삭제 \n",
    "\n",
    "print(X_train.shape,X_val.shape,Y_train.shape,Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = len(X_train) \n",
    "nb_validation_samples = len(X_val) \n",
    "batch_size = 2\n",
    "train_datagen = ImageDataGenerator( \n",
    "    rescale=1. / 255, \n",
    "    shear_range=0.2, \n",
    "    zoom_range=0.2, \n",
    "    horizontal_flip=True) \n",
    "\n",
    "val_datagen = ImageDataGenerator( \n",
    "    rescale=1. / 255, \n",
    "    shear_range=0.2, \n",
    "    zoom_range=0.2, \n",
    "    horizontal_flip=True) \n",
    "\n",
    "train_generator = train_datagen.flow(np.array(X_train), Y_train, batch_size=batch_size) \n",
    "validation_generator = val_datagen.flow(np.array(X_val), Y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 79, 79, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 79, 79, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 79, 79, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 77, 77, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 77, 77, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 77, 77, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 77, 77, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 77, 77, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 77, 77, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 38, 38, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 38, 38, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 38, 38, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 38, 38, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 36, 36, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 36, 36, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 36, 36, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 17, 17, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 17, 17, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 17, 17, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 17, 17, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 17, 17, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 17, 17, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 17, 17, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 17, 17, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 17, 17, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 17, 17, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 17, 17, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 17, 17, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 17, 17, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 17, 17, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 17, 17, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 17, 17, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 17, 17, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 17, 17, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 17, 17, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 17, 17, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 17, 17, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 17, 17, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 17, 17, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 17, 17, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 17, 17, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 17, 17, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 17, 17, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 17, 17, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 17, 17, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 17, 17, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 17, 17, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 17, 17, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 17, 17, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 17, 17, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 17, 17, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 17, 17, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 17, 17, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 17, 17, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 17, 17, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 17, 17, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 17, 17, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 17, 17, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 17, 17, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 17, 17, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 17, 17, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 17, 17, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 17, 17, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 17, 17, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 17, 17, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 17, 17, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 17, 17, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 17, 17, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 17, 17, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 17, 17, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 17, 17, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 17, 17, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 17, 17, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 17, 17, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 17, 17, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 17, 17, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 17, 17, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 17, 17, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 17, 17, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 17, 17, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 17, 17, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 17, 17, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 17, 17, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 17, 17, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 17, 17, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 17, 17, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 17, 17, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 17, 17, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 17, 17, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 17, 17, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 17, 17, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 17, 17, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 8, 8, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 8, 8, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 8, 8, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 8, 8, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 8, 8, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 8, 8, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 8, 8, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 8, 8, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 8, 8, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 8, 8, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 8, 8, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 8, 8, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 8, 8, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 8, 8, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 8, 8, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 8, 8, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 8, 8, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 8, 8, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 8, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 8, 8, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 8, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 8, 8, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 8, 8, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 8, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 8, 8, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 8, 8, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 8, 8, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 8, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 8, 8, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 8, 8, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 8, 8, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 8, 8, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 8, 8, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 8, 8, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 8, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 8, 8, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 8, 8, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 8, 8, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 8, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 8, 8, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 8, 8, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 8, 8, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 192)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 192)    258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 8, 8, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 8, 8, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 8, 8, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 8, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "last layer output shape:  (None, 8, 8, 768)\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape=(160, 160, 3),\n",
    "                              include_top=False,\n",
    "                              weights=None)\n",
    "pre_trained_model.summary()\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output.shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model2 = Model(pre_trained_model.input, x)\n",
    "\n",
    "model2.compile(optimizer='adam',   #RMSprop(lr=0.001),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-621fe29c9b63>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/60\n",
      "376/376 [==============================] - 304s 809ms/step - loss: 6.5506 - accuracy: 0.4707 - val_loss: 1.2030 - val_accuracy: 0.6117\n",
      "Epoch 2/60\n",
      "376/376 [==============================] - 301s 801ms/step - loss: 1.0877 - accuracy: 0.6117 - val_loss: 1.1193 - val_accuracy: 0.6117\n",
      "Epoch 3/60\n",
      "376/376 [==============================] - 306s 813ms/step - loss: 1.0197 - accuracy: 0.6316 - val_loss: 0.9390 - val_accuracy: 0.6489\n",
      "Epoch 4/60\n",
      "376/376 [==============================] - 299s 794ms/step - loss: 0.9722 - accuracy: 0.6370 - val_loss: 1.0205 - val_accuracy: 0.6223\n",
      "Epoch 5/60\n",
      "376/376 [==============================] - 277s 738ms/step - loss: 0.9730 - accuracy: 0.6436 - val_loss: 0.9274 - val_accuracy: 0.6489\n",
      "Epoch 6/60\n",
      "376/376 [==============================] - 277s 736ms/step - loss: 1.0030 - accuracy: 0.6343 - val_loss: 1.0237 - val_accuracy: 0.6489\n",
      "Epoch 7/60\n",
      "376/376 [==============================] - 276s 735ms/step - loss: 0.9930 - accuracy: 0.6410 - val_loss: 1.3510 - val_accuracy: 0.6436\n",
      "Epoch 8/60\n",
      "376/376 [==============================] - 278s 740ms/step - loss: 0.9757 - accuracy: 0.6223 - val_loss: 0.9540 - val_accuracy: 0.6383\n",
      "Epoch 9/60\n",
      "376/376 [==============================] - 276s 735ms/step - loss: 0.9584 - accuracy: 0.6316 - val_loss: 1.0081 - val_accuracy: 0.6011\n",
      "Epoch 10/60\n",
      "376/376 [==============================] - 277s 735ms/step - loss: 0.9389 - accuracy: 0.6343 - val_loss: 0.8996 - val_accuracy: 0.6436\n",
      "Epoch 11/60\n",
      "376/376 [==============================] - 277s 736ms/step - loss: 0.9126 - accuracy: 0.6476 - val_loss: 1.2250 - val_accuracy: 0.6277\n",
      "Epoch 12/60\n",
      "376/376 [==============================] - 277s 736ms/step - loss: 0.9710 - accuracy: 0.6370 - val_loss: 1.1603 - val_accuracy: 0.6543\n",
      "Epoch 13/60\n",
      "376/376 [==============================] - 277s 736ms/step - loss: 0.9243 - accuracy: 0.6529 - val_loss: 1.9472 - val_accuracy: 0.3457\n",
      "Epoch 14/60\n",
      "376/376 [==============================] - 277s 736ms/step - loss: 0.9101 - accuracy: 0.6556 - val_loss: 1.0894 - val_accuracy: 0.6011\n",
      "Epoch 15/60\n",
      "376/376 [==============================] - 277s 735ms/step - loss: 0.8455 - accuracy: 0.6848 - val_loss: 0.8402 - val_accuracy: 0.6755\n",
      "Epoch 16/60\n",
      "376/376 [==============================] - 276s 735ms/step - loss: 0.8580 - accuracy: 0.6636 - val_loss: 0.8746 - val_accuracy: 0.6702\n",
      "Epoch 17/60\n",
      "376/376 [==============================] - 277s 738ms/step - loss: 0.8896 - accuracy: 0.6875 - val_loss: 1.1525 - val_accuracy: 0.6011\n",
      "Epoch 18/60\n",
      "376/376 [==============================] - 276s 735ms/step - loss: 0.8815 - accuracy: 0.6822 - val_loss: 1.6200 - val_accuracy: 0.5479\n",
      "Epoch 19/60\n",
      "376/376 [==============================] - 277s 736ms/step - loss: 0.7933 - accuracy: 0.6981 - val_loss: 1.3931 - val_accuracy: 0.5691\n",
      "Epoch 20/60\n",
      "376/376 [==============================] - 277s 736ms/step - loss: 0.7758 - accuracy: 0.7088 - val_loss: 0.8792 - val_accuracy: 0.6862\n",
      "Epoch 21/60\n",
      "376/376 [==============================] - 277s 736ms/step - loss: 0.7968 - accuracy: 0.7141 - val_loss: 3.1363 - val_accuracy: 0.5372\n",
      "Epoch 22/60\n",
      "376/376 [==============================] - 277s 736ms/step - loss: 0.7720 - accuracy: 0.7234 - val_loss: 0.9682 - val_accuracy: 0.6809\n",
      "Epoch 23/60\n",
      "376/376 [==============================] - 277s 736ms/step - loss: 0.6615 - accuracy: 0.7434 - val_loss: 0.7274 - val_accuracy: 0.7181\n",
      "Epoch 24/60\n",
      "376/376 [==============================] - 277s 736ms/step - loss: 0.6621 - accuracy: 0.7540 - val_loss: 0.6085 - val_accuracy: 0.7447\n",
      "Epoch 25/60\n",
      "376/376 [==============================] - 277s 736ms/step - loss: 0.6540 - accuracy: 0.7367 - val_loss: 0.7137 - val_accuracy: 0.7128\n",
      "Epoch 26/60\n",
      "376/376 [==============================] - 277s 736ms/step - loss: 0.6218 - accuracy: 0.7367 - val_loss: 0.7197 - val_accuracy: 0.7128\n",
      "Epoch 27/60\n",
      "376/376 [==============================] - 277s 737ms/step - loss: 0.6433 - accuracy: 0.7487 - val_loss: 0.6221 - val_accuracy: 0.7606\n",
      "Epoch 28/60\n",
      "376/376 [==============================] - 278s 738ms/step - loss: 0.5883 - accuracy: 0.7460 - val_loss: 0.6234 - val_accuracy: 0.7287\n",
      "Epoch 29/60\n",
      "376/376 [==============================] - 306s 814ms/step - loss: 0.5975 - accuracy: 0.7487 - val_loss: 0.7820 - val_accuracy: 0.5957\n",
      "Epoch 30/60\n",
      "376/376 [==============================] - 18296s 49s/step - loss: 0.7865 - accuracy: 0.7101 - val_loss: 0.8166 - val_accuracy: 0.7074\n",
      "Epoch 31/60\n",
      "376/376 [==============================] - 321s 855ms/step - loss: 0.6644 - accuracy: 0.7407 - val_loss: 0.9652 - val_accuracy: 0.6596\n",
      "Epoch 32/60\n",
      "376/376 [==============================] - 313s 831ms/step - loss: 0.5929 - accuracy: 0.7553 - val_loss: 0.5826 - val_accuracy: 0.7234\n",
      "Epoch 33/60\n",
      "376/376 [==============================] - 304s 809ms/step - loss: 0.5447 - accuracy: 0.7646 - val_loss: 0.7822 - val_accuracy: 0.7234\n",
      "Epoch 34/60\n",
      "376/376 [==============================] - 313s 831ms/step - loss: 0.5759 - accuracy: 0.7660 - val_loss: 0.5156 - val_accuracy: 0.7979\n",
      "Epoch 35/60\n",
      "376/376 [==============================] - 306s 814ms/step - loss: 0.5652 - accuracy: 0.7686 - val_loss: 0.7376 - val_accuracy: 0.6436\n",
      "Epoch 36/60\n",
      "376/376 [==============================] - 306s 815ms/step - loss: 0.5420 - accuracy: 0.7739 - val_loss: 0.5861 - val_accuracy: 0.7394\n",
      "Epoch 37/60\n",
      "376/376 [==============================] - 304s 809ms/step - loss: 0.5044 - accuracy: 0.7992 - val_loss: 0.6453 - val_accuracy: 0.7234\n",
      "Epoch 38/60\n",
      "376/376 [==============================] - 305s 812ms/step - loss: 0.5600 - accuracy: 0.7859 - val_loss: 0.5783 - val_accuracy: 0.7340\n",
      "Epoch 39/60\n",
      "376/376 [==============================] - 304s 810ms/step - loss: 0.5484 - accuracy: 0.7766 - val_loss: 0.6830 - val_accuracy: 0.7340\n",
      "Epoch 40/60\n",
      "376/376 [==============================] - 304s 809ms/step - loss: 0.5372 - accuracy: 0.7899 - val_loss: 0.5867 - val_accuracy: 0.7713\n",
      "Epoch 41/60\n",
      "376/376 [==============================] - 308s 818ms/step - loss: 0.5693 - accuracy: 0.7899 - val_loss: 0.6915 - val_accuracy: 0.7021\n",
      "Epoch 42/60\n",
      "376/376 [==============================] - 305s 812ms/step - loss: 0.5497 - accuracy: 0.7939 - val_loss: 0.5646 - val_accuracy: 0.7819\n",
      "Epoch 43/60\n",
      "376/376 [==============================] - 305s 812ms/step - loss: 0.4816 - accuracy: 0.8072 - val_loss: 0.5604 - val_accuracy: 0.8085\n",
      "Epoch 44/60\n",
      "376/376 [==============================] - 11200s 30s/step - loss: 0.4998 - accuracy: 0.7886 - val_loss: 0.5160 - val_accuracy: 0.7872\n",
      "Epoch 45/60\n",
      "376/376 [==============================] - 305s 811ms/step - loss: 0.4598 - accuracy: 0.8125 - val_loss: 0.6166 - val_accuracy: 0.6968\n",
      "Epoch 46/60\n",
      "376/376 [==============================] - 304s 809ms/step - loss: 0.5000 - accuracy: 0.8045 - val_loss: 0.5411 - val_accuracy: 0.7979\n",
      "Epoch 47/60\n",
      "376/376 [==============================] - 309s 821ms/step - loss: 0.4826 - accuracy: 0.8085 - val_loss: 0.5702 - val_accuracy: 0.7926\n",
      "Epoch 48/60\n",
      "376/376 [==============================] - 306s 815ms/step - loss: 0.4639 - accuracy: 0.7899 - val_loss: 0.4967 - val_accuracy: 0.8085\n",
      "Epoch 49/60\n",
      "376/376 [==============================] - 305s 812ms/step - loss: 0.4597 - accuracy: 0.8218 - val_loss: 0.5614 - val_accuracy: 0.7819\n",
      "Epoch 50/60\n",
      "376/376 [==============================] - 307s 816ms/step - loss: 0.5119 - accuracy: 0.7965 - val_loss: 0.4960 - val_accuracy: 0.7766\n",
      "Epoch 51/60\n",
      "376/376 [==============================] - 306s 814ms/step - loss: 0.4686 - accuracy: 0.8205 - val_loss: 0.5912 - val_accuracy: 0.7074\n",
      "Epoch 52/60\n",
      "376/376 [==============================] - 308s 819ms/step - loss: 0.4700 - accuracy: 0.7992 - val_loss: 0.4870 - val_accuracy: 0.7766\n",
      "Epoch 53/60\n",
      "376/376 [==============================] - 306s 813ms/step - loss: 0.4623 - accuracy: 0.8112 - val_loss: 0.5223 - val_accuracy: 0.7660\n",
      "Epoch 54/60\n",
      "376/376 [==============================] - 306s 813ms/step - loss: 0.4672 - accuracy: 0.8059 - val_loss: 0.5895 - val_accuracy: 0.7553\n",
      "Epoch 55/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 303s 806ms/step - loss: 0.5005 - accuracy: 0.8045 - val_loss: 0.7599 - val_accuracy: 0.7287\n",
      "Epoch 56/60\n",
      "376/376 [==============================] - 11199s 30s/step - loss: 0.4540 - accuracy: 0.8231 - val_loss: 0.7274 - val_accuracy: 0.7819\n",
      "Epoch 57/60\n",
      "376/376 [==============================] - 304s 809ms/step - loss: 0.4345 - accuracy: 0.8258 - val_loss: 0.5119 - val_accuracy: 0.7819\n",
      "Epoch 58/60\n",
      "376/376 [==============================] - 304s 808ms/step - loss: 0.4315 - accuracy: 0.8258 - val_loss: 0.4756 - val_accuracy: 0.8138\n",
      "Epoch 59/60\n",
      "376/376 [==============================] - 303s 807ms/step - loss: 0.4520 - accuracy: 0.8231 - val_loss: 0.5597 - val_accuracy: 0.7979\n",
      "Epoch 60/60\n",
      "376/376 [==============================] - 304s 808ms/step - loss: 0.4440 - accuracy: 0.8258 - val_loss: 0.5132 - val_accuracy: 0.7872\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=60,\n",
    "    validation_data=validation_generator, \n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model2.save('Fruit_MultiClassification_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
